{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for ukrainian and russian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\", limit = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\", limit = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0000001192092896),\n",
       " ('июль', 0.938315212726593),\n",
       " ('сентябрь', 0.9240026473999023),\n",
       " ('июнь', 0.9222574830055237),\n",
       " ('октябрь', 0.9095540046691895),\n",
       " ('ноябрь', 0.893003523349762),\n",
       " ('апрель', 0.8729085326194763),\n",
       " ('декабрь', 0.86525559425354),\n",
       " ('март', 0.8545794486999512),\n",
       " ('февраль', 0.8401417136192322)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 1.0000003576278687),\n",
       " ('липень', 0.9096442461013794),\n",
       " ('вересень', 0.9016972780227661),\n",
       " ('червень', 0.8992522358894348),\n",
       " ('жовтень', 0.8810408711433411),\n",
       " ('листопад', 0.8787632584571838),\n",
       " ('квітень', 0.8592804074287415),\n",
       " ('грудень', 0.8586865067481995),\n",
       " ('травень', 0.8408110737800598),\n",
       " ('лютий', 0.8256436586380005)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('одностороннего', 0.2260887771844864),\n",
       " ('подход', 0.22305867075920105),\n",
       " ('конструктивное', 0.21656127274036407),\n",
       " ('подхода', 0.21423815190792084),\n",
       " ('аспектах', 0.21134454011917114),\n",
       " ('двустороннего', 0.2105553299188614),\n",
       " ('Продление', 0.20925389230251312),\n",
       " ('Подход', 0.2089262455701828),\n",
       " ('прикладного', 0.2064727395772934),\n",
       " ('Правовое', 0.2055036574602127)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small dictionaries for correspoinding words pairs as trainset and testset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename, src_emb, dst_emb, ch):\n",
    "    pairs = []\n",
    "    src_vectors = []\n",
    "    dst_vectors = []\n",
    "    with open(filename, \"r\", encoding='UTF8') as inpf:\n",
    "        for line in inpf:\n",
    "            src_word, dst_word = line.rstrip().split(ch)\n",
    "            if src_word not in src_emb or dst_word not in dst_emb:\n",
    "                continue\n",
    "            pairs.append((src_word, dst_word))\n",
    "            src_vectors.append(src_emb[src_word])\n",
    "            dst_vectors.append(dst_emb[dst_word])\n",
    "    return pairs, np.array(src_vectors), np.array(dst_vectors)\n",
    "\n",
    "def load_uk_rus_word_pairs(filename):\n",
    "    return load_word_pairs(filename, uk_emb, ru_emb, \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_uk_rus_word_pairs(\"ukr_rus_train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding space mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "\n",
    "or $$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm.\n",
    "\n",
    "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5865652846250251\n",
      "[[-0.07448176  0.02855698  0.0047728  ...  0.05515353  0.07882916\n",
      "   0.02582788]\n",
      " [-0.02114187  0.05680199  0.03354491 ...  0.0437839   0.01170793\n",
      "   0.01858522]\n",
      " [ 0.14141488 -0.02344783  0.04475067 ... -0.00047044  0.04203068\n",
      "  -0.03964037]\n",
      " ...\n",
      " [ 0.02423559  0.01803976 -0.04328813 ... -0.0570966   0.07869118\n",
      "  -0.01255331]\n",
      " [ 0.00024544  0.01675807 -0.00442109 ...  0.05399176  0.07159237\n",
      "  -0.05868448]\n",
      " [-0.04930566 -0.02664137 -0.03720214 ...  0.03776147  0.021207\n",
      "  -0.0337888 ]]\n"
     ]
    }
   ],
   "source": [
    "print(mapping.score(X_train, Y_train))\n",
    "print(mapping.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a look at neigbours of the vector of word \"серпень\" (\"август\" in Russian) after linear transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8620684146881104),\n",
       " ('июнь', 0.8531144261360168),\n",
       " ('март', 0.8480013012886047),\n",
       " ('сентябрь', 0.847731351852417),\n",
       " ('октябрь', 0.843162477016449),\n",
       " ('февраль', 0.8424291610717773),\n",
       " ('ноябрь', 0.840266764163971),\n",
       " ('июль', 0.8354388475418091),\n",
       " ('август', 0.8232010006904602),\n",
       " ('декабрь', 0.8181028366088867)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мяу:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кот', 0.7645192742347717),\n",
       " ('котик', 0.6762053966522217),\n",
       " ('щенок', 0.6658127903938293),\n",
       " ('пес', 0.6568678021430969),\n",
       " ('котенок', 0.6546682119369507),\n",
       " ('кошка', 0.6465268731117249),\n",
       " ('кролик', 0.6448255181312561),\n",
       " ('пёс', 0.628338098526001),\n",
       " ('хомяк', 0.6185213327407837),\n",
       " ('заяц', 0.6175107955932617)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cat = mapping.predict(uk_emb[\"кіт\"].reshape(1, -1))\n",
    "ru_emb.most_similar(cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place.\n",
    "\n",
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, emb, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, dst) in enumerate(pairs):\n",
    "        similar = emb.most_similar([mapped_vectors[i]],topn=topn)\n",
    "        for word, p in similar:\n",
    "            if dst == word:\n",
    "                num_matches += 1\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, ru_emb, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, ru_emb, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, ru_emb, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_uk_rus_word_pairs(\"ukr_rus_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, X_test, ru_emb) == 0.0\n",
    "assert precision(uk_ru_test, Y_test, ru_emb) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, model.predict(X_test), ru_emb, 1)\n",
    "precision_top5 = precision(uk_ru_test, model.predict(X_test), ru_emb, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6744186046511628\n",
      "0.8255813953488372\n"
     ]
    }
   ],
   "source": [
    "print(precision_top1)\n",
    "print(precision_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making it better (orthogonal Procrustean problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    ":returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "\"\"\"\n",
    "\n",
    "def learn_transform(X, Y):\n",
    "    U, s, V = np.linalg.svd(np.matmul(X_train.T,Y_train))\n",
    "    W = np.matmul(U,V)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6831395348837209\n",
      "0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "print(precision(uk_ru_test, np.matmul(X_test, W), ru_emb))\n",
    "print(precision(uk_ru_test, np.matmul(X_test, W), ru_emb, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK-RU Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":args:\n",
    "    sentence - sentence in Ukrainian (str)\n",
    ":returns:\n",
    "    translation - sentence in Russian (str)\n",
    "\n",
    "* find ukrainian embedding for each word in sentence\n",
    "* transform ukrainian embedding vector\n",
    "* find nearest russian word and replace\n",
    "\"\"\"\n",
    "\n",
    "def translate(sentence):\n",
    "    # YOUR CODE HERE\n",
    "    words = sentence.split(\" \")\n",
    "    translation = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            emb = uk_emb[word]\n",
    "            translation.append(ru_emb.most_similar([np.matmul(emb, W)], topn=1)[0][0])           \n",
    "        except:\n",
    "            translation.append(word)\n",
    "    return \" \".join(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fairy_tale.txt\", \"r\", encoding='UTF8') as inpf:\n",
    "    uk_sentences = [line.rstrip().lower() for line in inpf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, src_emb, dst_emb):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "    words = sentence.split(' ')\n",
    "    translation = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            ru_word = dst_emb.most_similar([np.matmul(src_emb[word], W)], topn=1)[0][0]\n",
    "            translation.append(ru_word)           \n",
    "        except:\n",
    "            translation.append(word)\n",
    "    return ' '.join(translation)\n",
    "\n",
    "def uk_ru_translate(sentence):\n",
    "    return translate(sentence, uk_emb, ru_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: лисичка - сестричка і вовк - панібрат\n",
      "dst: лисичка – сестричка и волк – панібрат\n",
      "\n",
      "src: як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !\n",
      "dst: как была себе лисичка , че и пошла раз к однії бабы добувать огню ; вошла во избу че и говорит : \" хороший день тебе , бабушку !\n",
      "\n",
      "src: дай мені огня \" .\n",
      "dst: дай мне огня \" .\n",
      "\n",
      "src: а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .\n",
      "dst: а бабка только что вийняла со печи пирожок со изюмом , сладкий , че и положила , чтобы он прохолов ; а лисичка ой и підгледала , че только что бабка нахилилась во печь , чтобы достать огня , то лисичка сейчас ухватила пирожок че и драла со избы , че , біжучи , весь мак со его виїла , а туда мусор отпустила .\n",
      "\n",
      "src: прибігла на поле , аж там пасуть хлопці бичків .\n",
      "dst: прибігла по поле , до там пасуть парни бичків .\n",
      "\n",
      "src: вона і каже їм : \" ей , хлопці !\n",
      "dst: она и говорит им : \" ой , парни !\n",
      "\n",
      "src: проміняйте мені бичка - третячка за маковий пирожок \" .\n",
      "dst: проміняйте мне бичка – третячка за маковий пирожок \" .\n",
      "\n",
      "src: тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .\n",
      "dst: тії согласились ; так она им говорит : \" смотріть то , мы не ешьте сейчас сего пирожка , а тогда уже розломите , как мной заведу бичка за могилку ; а то мы его ни за что не розломите \" .\n",
      "\n",
      "src: бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .\n",
      "dst: видишь уже – лисичка таки себе была умная , что хоть кого че обманить .\n",
      "\n",
      "src: тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .\n",
      "dst: тії парни так и сделали , а лисичка как зашла за могилу , че сейчас во лес и вернула , чтобы по дороге не догнали ; пришла во лес че и сделала себе санки че и едет .\n",
      "\n",
      "src: коли йде вовчик : \" здорова була , лисичко - сестричко ! \"\n",
      "dst: когда идет вовчик : \" здоровая была , лисичко – сестричко ! \"\n",
      "\n",
      "src: - \" здоров , вовчику - братику ! \"\n",
      "dst: – \" здоровье , вовчику – братику ! \"\n",
      "\n",
      "src: - \" де се ти узяла собі і бичка і санки ? \"\n",
      "dst: – \" куда ой ты взяла себе и бичка и санки ? \"\n",
      "\n",
      "src: - \" е !\n",
      "dst: – \" ой !\n",
      "\n",
      "src: зробила \" .\n",
      "dst: сделала \" .\n",
      "\n",
      "src: - \" підвези ж і мене \" .\n",
      "dst: – \" підвези же и меня \" .\n",
      "\n",
      "src: - \" е , вовчику !\n",
      "dst: – \" ой , вовчику !\n",
      "\n",
      "src: не можна \" .\n",
      "dst: не можно \" .\n",
      "\n",
      "src: - \" мені хоть одну ніжку \" .\n",
      "dst: – \" мне хоть одну ножку \" .\n",
      "\n",
      "src: - \" одну можна \" .\n",
      "dst: – \" одну можно \" .\n",
      "\n",
      "src: він і положив , да од'їхавши немного і просить , щоби іще одну положить .\n",
      "dst: он и положив , че од'їхавши немного и просит , чтобы еще одну положить .\n",
      "\n",
      "src: \" не можна , братику !\n",
      "dst: \" не можно , братику !\n",
      "\n",
      "src: боюсь , щоб ти саней не зламав \" .\n",
      "dst: боюсь , чтобы ты саней не сломал \" .\n",
      "\n",
      "src: - \" ні , сестричко , не бійся ! \"\n",
      "dst: – \" ни , сестричко , не бойся ! \"\n",
      "\n",
      "src: - да і положив другую ніжку .\n",
      "dst: – че и положив другую ножку .\n",
      "\n",
      "src: тілько що од'їхали , як щось і тріснуло .\n",
      "dst: только что од'їхали , как что-то и тріснуло .\n",
      "\n",
      "src: \" бачиш , вовчику , уже і ламаєш санки \" .\n",
      "dst: \" видишь , вовчику , уже и ламаєш санки \" .\n",
      "\n",
      "src: - \" ні , лисичко !\n",
      "dst: – \" ни , лисичко !\n",
      "\n",
      "src: се у мене був орішок , так я розкусив \" .\n",
      "dst: ой во меня был орішок , так мной розкусив \" .\n",
      "\n",
      "src: да просить оп'ять , щоб і третю ногу положить ; лисичка і ту пустила , да тілько що оп'ять од'їхали , аж щось уже дужче тріснуло .\n",
      "dst: че просит оп'ять , чтобы и третью ногу положить ; лисичка и ту пустила , че только что оп'ять од'їхали , до что-то уже сильней тріснуло .\n",
      "\n",
      "src: лисичка закричала : \" ох , лишечко !\n",
      "dst: лисичка закричала : \" ой , лишечко !\n",
      "\n",
      "src: ти ж мені , братику , зовсім зламаєш санки \" .\n",
      "dst: ты же мне , братику , совсем зламаєш санки \" .\n",
      "\n",
      "src: - \" ні , лисичко , се я орішок розкусив \" .\n",
      "dst: – \" ни , лисичко , ой мной орішок розкусив \" .\n",
      "\n",
      "src: - \" дай же і мені , бачиш який , що сам їж , а мені і не даєш \" .\n",
      "dst: – \" дай то и мне , видишь который , что сам ел , а мне и не даєш \" .\n",
      "\n",
      "src: - \" нема уже більше , а я б дав \" .\n",
      "dst: – \" нету уже больше , а мной бы дал \" .\n",
      "\n",
      "src: да і просить оп'ять , щоб пустила положить і послідню ногу .\n",
      "dst: че и просит оп'ять , чтобы пустила положить и послідню ногу .\n",
      "\n",
      "src: лисичка і согласилась .\n",
      "dst: лисичка и согласилась .\n",
      "\n",
      "src: так він тілько що положив ногу , як санки зовсім розламались .\n",
      "dst: так он только что положив ногу , как санки совсем розламались .\n",
      "\n",
      "src: тоді вже лисичка так на його розсердилась , що і сама не знала щоб робила !\n",
      "dst: тогда уже лисичка так по его розсердилась , что и сама не знала чтобы делала !\n",
      "\n",
      "src: а як отошло серце , вона і каже : \" іди ж , ледащо !\n",
      "dst: а как отошло сердце , она и говорит : \" иди же , ледащо !\n",
      "\n",
      "src: да нарубай дерева , щоб нам оп'ять ізробить санки ; тільки рубавши кажи так : \" рубайся ж , дерево , і криве і пряме \" .\n",
      "dst: че нарубай дерева , чтобы нам оп'ять ізробить санки ; только рубавши говори так : \" рубайся же , дерево , и криве и прямое \" .\n",
      "\n",
      "src: він і пішов да й каже усе : \" рубайся ж , дерево , усе пряме да пряме ! \"\n",
      "dst: он и пошел че и говорит всё : \" рубайся же , дерево , всё прямое че прямое ! \"\n",
      "\n",
      "src: нарубавши і приносить ; лисичка увидала , що дерево не таке , як їй нужно , оп'ять розсердилась .\n",
      "dst: нарубавши и приносит ; лисичка увидала , что дерево не такое , как им надо , оп'ять розсердилась .\n",
      "\n",
      "src: \" ти , - говорить , - не казав , видно , так , як я тобі веліла ! \"\n",
      "dst: \" ты , – говорит , – не говорил , видно , так , как мной тебе веліла ! \"\n",
      "\n",
      "src: - \" ні , я усе теє казав , що ти мені казала \" .\n",
      "dst: – \" ни , мной всё теє говорил , что ты мне говорила \" .\n",
      "\n",
      "src: - \" да чомусь не таке рубалось ?\n",
      "dst: – \" че почему-то не такое рубалось ?\n",
      "\n",
      "src: ну , сиди ж ти тут , а я сама піду нарубаю \" , - да і пішла у ліс .\n",
      "dst: ну , сиди же ты здесь , а мной сама пойду нарубаю \" , – че и пошла во лес .\n",
      "\n",
      "src: а вовк дивиться , що він сам остався ; узяв да проїв у бичка дірку да виїв усе в середині , а напускав туда горобців да ще соломою заткнув , поставив бичка , а сам і втік .\n",
      "dst: а волк смотрит , что он сам остався ; взял че проїв во бичка дыру че виїв всё во середине , а напускав туда горобців че же соломы заткнув , поставил бичка , а сам и сбежал .\n",
      "\n",
      "src: аж лисичка приходить , зробила санки да й сіла і стала поганять : \" гей , бичок - третячок ! \"\n",
      "dst: до лисичка приходит , сделала санки че и присела и стала поганять : \" гей , бичок – третячок ! \"\n",
      "\n",
      "src: тілько він не везе .\n",
      "dst: только он не привозит .\n",
      "\n",
      "src: от вона встала , щоб поправить : може , що не так запряжено ; да , не хотячи , одоткнула солому , а оттуда так і сипнули горобці летіти .\n",
      "dst: из она встала , чтобы поправить : может , что не так запряжено ; че , не хотячи , одоткнула сено , а оттуда так и сипнули горобці лететь .\n",
      "\n",
      "src: вона уже тоді побачила , що бичок неживий ; покинула його да й пішла .\n",
      "dst: она уже тогда увидела , что бичок неживий ; покинула его че и пошла .\n",
      "\n",
      "src: легла на дорозі , аж дивиться - їде мужик з рибою ; вона і притворилась , що здохла .\n",
      "dst: легла по дороге , до смотрит – едет мужик со рыбой ; она и притворилась , что здохла .\n",
      "\n",
      "src: от мужик і говорить : \" возьму я оцю лисицю , обдеру да хоть шапку собі зошью \" .\n",
      "dst: из мужик и говорит : \" возьму мной оцю лисицю , обдеру че хоть шапку себе зошью \" .\n",
      "\n",
      "src: узяв да і положив ззаді у воза .\n",
      "dst: взял че и положив ззаді во повозки .\n",
      "\n",
      "src: вона замітила , що мужик не смотрить , стала ногами викидувать рибу з воза , а когда побачила , що навикидала уже багато , тоди потихесеньку і сама злізла ; сіла біля риби да і їсть собі , - коли біжить оп'ять той самий вовчик .\n",
      "dst: она замітила , что мужик не смотрить , стала ногами викидувать рыбу со повозки , а когда увидела , что навикидала уже много , тоди потихесеньку и сама злізла ; присела возле рыбы че и ест себе , – когда бежит оп'ять тот самый вовчик .\n",
      "\n",
      "src: побачивши , що вона їсть рибу , прибіг до їй да й каже : \" здорово була , лисичко - сестричко !\n",
      "dst: увидев , что она ест рыбу , прибіг к им че и говорит : \" здорово была , лисичко – сестричко !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: де се ти набрала стільки риби ? \"\n",
      "dst: куда ой ты набрала столько рыбы ? \"\n",
      "\n",
      "src: вона каже : \" наловила , вовчику - братику ! \"\n",
      "dst: она говорит : \" наловила , вовчику – братику ! \"\n",
      "\n",
      "src: а собі на думці : \" подожди , і я зроблю з тобою таку штуку , як і ти зо мною \" .\n",
      "dst: а себе по мнении : \" подожди , и мной сделаю со тобой такую штуку , как и ты За мной \" .\n",
      "\n",
      "src: - \" як же ти ловила ? \"\n",
      "dst: – \" как то ты ловила ? \"\n",
      "\n",
      "src: - \" так , вовчику , уложила хвостик в ополонку , вожу тихенько да й кажу ; ловися , рибка , мала і велика !\n",
      "dst: – \" так , вовчику , уложила хвостик во ополонку , вожу тихонько че и говорю ; ловися , рыбка , имела и большая !\n",
      "\n",
      "src: коли хочеш , то і ти піди , налови собі \" .\n",
      "dst: когда хочешь , то и ты піди , налови себе \" .\n",
      "\n",
      "src: він побіг да зробив так , як казала лисичка .\n",
      "dst: он побежал че сделал так , как говорила лисичка .\n",
      "\n",
      "src: а лисичка стала за деревом да й дивиться ; коли у вовчика зовсім хвостик примерз , вона тоді побігла в село да й кричить : \" ідіть , люди , вбивайте вовка ! \"\n",
      "dst: а лисичка стала за деревом че и смотрит ; когда во вовчика совсем хвостик примерз , она тогда побежала во село че и кричит : \" ідіть , люди , вбивайте волка ! \"\n",
      "\n",
      "src: люди набігли з кольями да і убили його .\n",
      "dst: люди набігли со кольями че и убили его .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in uk_sentences:\n",
    "    print(\"src: {}\\ndst: {}\\n\".format(sentence, uk_ru_translate(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'кот поймал мышку'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_ru_translate(\"кіт зловив мишу\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German and English languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for German and English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_emb = KeyedVectors.load_word2vec_format(\"cc.en.300.vec.gz\",binary=False, limit = 10000)\n",
    "de_emb = KeyedVectors.load_word2vec_format(\"cc.de.300.vec.gz\",binary=False, limit = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matrix for orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Orth(M):\n",
    "    Id = np.matmul(M, M.T)\n",
    "    assert (Id.shape[0] == Id.shape[1])\n",
    "    assert isMatrixEquals(Id, np.eye(Id.shape[0], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matrices for equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Matrix_Equals(M1, M2):\n",
    "    for i in range(M1.shape[0]):\n",
    "        for j in range(M1.shape[1]):\n",
    "            if abs(M1[i][j] - M2[i][j]) >= 0.01:\n",
    "                print(\"FALSE\")\n",
    "                return False\n",
    "    print(\"TRUE\")        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkResults(pairs, X, Y, emb, words_num):\n",
    "    # Get two transform matrices M1Frob and M2Frob for first 300 pairs and next 300 pairs respectively\n",
    "    l = words_num\n",
    "    h = words_num * 2 + 1\n",
    "    M1 = learn_transform(X[:l], Y[:l])\n",
    "    M2 = learn_transform(X[l:h], Y[l:h])\n",
    "    # Calculate precision for M1Frob and M2Frob on different sets of pairs\n",
    "    print(\"pair1 M1 topn = 5: {}\".format(precision(pairs[:l], np.matmul(X[:l], M1), emb, 5)))\n",
    "    print(\"pair1 M1 topn = 1: {}\".format(precision(pairs[:l], np.matmul(X[:l], M1), emb)))\n",
    "    print(\"pair1 M2 topn = 5: {}\".format(precision(pairs[:l], np.matmul(X[:l], M2), emb, 5)))\n",
    "    print(\"pair1 M2 topn = 1: {}\".format(precision(pairs[:l], np.matmul(X[:l], M2), emb)))\n",
    "    print(\"pair2 M1 topn = 5: {}\".format(precision(pairs[l:h], np.matmul(X[l:h], M1), emb, 5)))\n",
    "    print(\"pair2 M1 topn = 1: {}\".format(precision(pairs[l:h], np.matmul(X[l:h], M1), emb)))\n",
    "    print(\"pair2 M2 topn = 5: {}\".format(precision(pairs[l:h], np.matmul(X[l:h], M2), emb, 5)))\n",
    "    print(\"pair2 M2 topn = 1: {}\".format(precision(pairs[l:h], np.matmul(X[l:h], M2), emb)))\n",
    "    # Calculte Frobenius norm for matrix - |M1 - M2|\n",
    "    M1_M2 = np.linalg.norm((M1 - M2), ord = 'fro')\n",
    "    print(\"|M1 - M2|: {}\".format(M1_M2))\n",
    "    # Calculte Frobenius norm for matrix - |M1 - M2|/|M1|\n",
    "    print(\"|M1 - M2|/|M1|: {}\".format(M1_M2/np.linalg.norm(M1, ord='fro')))\n",
    "    # Check orthogonality\n",
    "    checkOrth(M1)\n",
    "    checkOrth(M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English to German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_en_de_word_pairs(filename):\n",
    "    return load_word_pairs(filename, en_emb, de_emb, \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for English and German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de_train, X_train, Y_train = load_en_de_word_pairs(\"en-de.0-5000.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de_test, X_test, Y_test = load_en_de_word_pairs(\"en-de.5000-6500.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1 topn = 5: 0.6766666666666666\n",
      "pair1 M1 topn = 1: 0.3233333333333333\n",
      "pair1 M2 topn = 5: 0.6766666666666666\n",
      "pair1 M2 topn = 1: 0.3233333333333333\n",
      "pair2 M1 topn = 5: 0.7906976744186046\n",
      "pair2 M1 topn = 1: 0.32558139534883723\n",
      "pair2 M2 topn = 5: 0.7906976744186046\n",
      "pair2 M2 topn = 1: 0.32558139534883723\n",
      "|M1 - M2|: 0.0\n",
      "|M1 - M2|/|M1|: 0.0\n"
     ]
    }
   ],
   "source": [
    "checkResults(en_de_train, X_train, Y_train, de_emb, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1 topn = 5: 0.76\n",
      "pair1 M1 topn = 1: 0.45666666666666667\n",
      "pair1 M2 topn = 5: 0.76\n",
      "pair1 M2 topn = 1: 0.45666666666666667\n",
      "pair2 M1 topn = 5: 0.7536231884057971\n",
      "pair2 M1 topn = 1: 0.5072463768115942\n",
      "pair2 M2 topn = 5: 0.7536231884057971\n",
      "pair2 M2 topn = 1: 0.5072463768115942\n",
      "|M1 - M2|: 0.0\n",
      "|M1 - M2|/|M1|: 0.0\n"
     ]
    }
   ],
   "source": [
    "checkResults(en_de_test, X_test, Y_test, de_emb, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "German to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_de_en_word_pairs(filename):\n",
    "    return load_word_pairs(filename, de_emb, en_emb, \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for German and English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_en_train, X_train, Y_train = load_de_en_word_pairs(\"de-en.0-5000.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_en_test, X_test, Y_test = load_de_en_word_pairs(\"de-en.5000-6500.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1 topn = 5: 0.8066666666666666\n",
      "pair1 M1 topn = 1: 0.4866666666666667\n",
      "pair1 M2 topn = 5: 0.8066666666666666\n",
      "pair1 M2 topn = 1: 0.4866666666666667\n",
      "pair2 M1 topn = 5: 0.7940199335548173\n",
      "pair2 M1 topn = 1: 0.42524916943521596\n",
      "pair2 M2 topn = 5: 0.7940199335548173\n",
      "pair2 M2 topn = 1: 0.42524916943521596\n",
      "|M1 - M2|: 0.0\n",
      "|M1 - M2|/|M1|: 0.0\n"
     ]
    }
   ],
   "source": [
    "checkResults(de_en_train, X_train, Y_train, en_emb, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1 topn = 5: 0.665\n",
      "pair1 M1 topn = 1: 0.36\n",
      "pair1 M2 topn = 5: 0.665\n",
      "pair1 M2 topn = 1: 0.36\n",
      "pair2 M1 topn = 5: 0.6923076923076923\n",
      "pair2 M1 topn = 1: 0.41208791208791207\n",
      "pair2 M2 topn = 5: 0.6923076923076923\n",
      "pair2 M2 topn = 1: 0.41208791208791207\n",
      "|M1 - M2|: 0.0\n",
      "|M1 - M2|/|M1|: 0.0\n"
     ]
    }
   ],
   "source": [
    "checkResults(de_en_test, X_test, Y_test, en_emb, 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
